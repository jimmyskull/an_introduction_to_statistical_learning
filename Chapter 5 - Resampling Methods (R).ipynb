{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 — Resampling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab — Cross-Validation and the Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Validation Set Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"ISLR\")\n",
    "library(\"ggplot2\")\n",
    "set.seed(1)\n",
    "train <- sample(392, 196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "26.1414211520072"
      ],
      "text/latex": [
       "26.1414211520072"
      ],
      "text/markdown": [
       "26.1414211520072"
      ],
      "text/plain": [
       "[1] 26.14142"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean((Auto$mpg - predict(lm.fit, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "19.8225850408262"
      ],
      "text/latex": [
       "19.8225850408262"
      ],
      "text/markdown": [
       "19.8225850408262"
      ],
      "text/plain": [
       "[1] 19.82259"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto,\n",
    "              subset = train)\n",
    "mean((Auto$mpg - predict(lm.fit2, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "19.7825166856023"
      ],
      "text/latex": [
       "19.7825166856023"
      ],
      "text/markdown": [
       "19.7825166856023"
      ],
      "text/plain": [
       "[1] 19.78252"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto,\n",
    "              subset = train)\n",
    "mean((Auto$mpg - predict(lm.fit3, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "23.2955851508862"
      ],
      "text/latex": [
       "23.2955851508862"
      ],
      "text/markdown": [
       "23.2955851508862"
      ],
      "text/plain": [
       "[1] 23.29559"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(2)\n",
    "train <- sample(392, 196)\n",
    "lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)\n",
    "mean((Auto$mpg - predict(lm.fit, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "18.9012408317778"
      ],
      "text/latex": [
       "18.9012408317778"
      ],
      "text/markdown": [
       "18.9012408317778"
      ],
      "text/plain": [
       "[1] 18.90124"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto,\n",
    "              subset = train)\n",
    "mean((Auto$mpg - predict(lm.fit2, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "19.2573982608642"
      ],
      "text/latex": [
       "19.2573982608642"
      ],
      "text/markdown": [
       "19.2573982608642"
      ],
      "text/plain": [
       "[1] 19.2574"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto,\n",
    "              subset = train)\n",
    "mean((Auto$mpg - predict(lm.fit3, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>39.9358610211705</dd>\n",
       "\t<dt>horsepower</dt>\n",
       "\t\t<dd>-0.157844733353654</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 39.9358610211705\n",
       "\\item[horsepower] -0.157844733353654\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   39.9358610211705horsepower\n",
       ":   -0.157844733353654\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 39.9358610  -0.1578447 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit <- glm(mpg ~ horsepower, data = Auto)\n",
    "coef(glm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>24.2315135179292</li>\n",
       "\t<li>24.2311440937562</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2315135179292\n",
       "\\item 24.2311440937562\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2315135179292\n",
       "2. 24.2311440937562\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 24.23151 24.23114"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(\"boot\")\n",
    "glm.fit <- glm(mpg ~ horsepower, data =  Auto)\n",
    "cv.err <- cv.glm(Auto, glm.fit)\n",
    "cv.err$delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`delta` is the vector of cross-validation results, given by\n",
    "$$\n",
    "\\text{CV}_{(k)} = \\frac{1}{k} \\sum_{i=1}^{k} \\text{MSE}_i\n",
    "$$\n",
    "where $k = n$ for the leave-one-out, which is the default of `cv.glm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>24.2315135179292</li>\n",
       "\t<li>19.2482131244897</li>\n",
       "\t<li>19.334984064029</li>\n",
       "\t<li>19.4244303104303</li>\n",
       "\t<li>19.0332138547041</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2315135179292\n",
       "\\item 19.2482131244897\n",
       "\\item 19.334984064029\n",
       "\\item 19.4244303104303\n",
       "\\item 19.0332138547041\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2315135179292\n",
       "2. 19.2482131244897\n",
       "3. 19.334984064029\n",
       "4. 19.4244303104303\n",
       "5. 19.0332138547041\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 24.23151 19.24821 19.33498 19.42443 19.03321"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv.error <- rep(0, 5)\n",
    "for (i in 1:5) {\n",
    "    glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)\n",
    "    cv.error[i] <- cv.glm(Auto, glm.fit)$delta[1]\n",
    "}\n",
    "cv.error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *k*-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>24.2051967567753</li>\n",
       "\t<li>19.1892390663471</li>\n",
       "\t<li>19.3066158967501</li>\n",
       "\t<li>19.3379909004929</li>\n",
       "\t<li>18.8791148363354</li>\n",
       "\t<li>19.0210341885228</li>\n",
       "\t<li>18.8960903802809</li>\n",
       "\t<li>19.7120146188182</li>\n",
       "\t<li>18.9514005667302</li>\n",
       "\t<li>19.501959228555</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2051967567753\n",
       "\\item 19.1892390663471\n",
       "\\item 19.3066158967501\n",
       "\\item 19.3379909004929\n",
       "\\item 18.8791148363354\n",
       "\\item 19.0210341885228\n",
       "\\item 18.8960903802809\n",
       "\\item 19.7120146188182\n",
       "\\item 18.9514005667302\n",
       "\\item 19.501959228555\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2051967567753\n",
       "2. 19.1892390663471\n",
       "3. 19.3066158967501\n",
       "4. 19.3379909004929\n",
       "5. 18.8791148363354\n",
       "6. 19.0210341885228\n",
       "7. 18.8960903802809\n",
       "8. 19.7120146188182\n",
       "9. 18.9514005667302\n",
       "10. 19.501959228555\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 24.20520 19.18924 19.30662 19.33799 18.87911 19.02103 18.89609 19.71201\n",
       " [9] 18.95140 19.50196"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(17)\n",
    "cv.error.10 <- rep(0, 10)\n",
    "for(i in 1:10) {\n",
    "    glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)\n",
    "    cv.error.10[i] <- cv.glm(Auto, glm.fit, K = 10)$delta[1]\n",
    "}\n",
    "cv.error.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the Accuracy of a Statistic of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s use the **Portfolio** data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple simulated data set containing 100 returns for each of two assets, X and Y. The data is used to estimate the optimal fraction to invest in each asset to minimize investment risk of the combined portfolio. One can then use the Bootstrap to estimate the standard error of this estimate.\n",
    "\n",
    "Name | Description\n",
    ":--- | :----------\n",
    "X    | Returns for Asset X\n",
    "Y    | Returns for Asset Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>X</th><th scope=col>Y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>-0.8952509</td><td>-0.2349235</td></tr>\n",
       "\t<tr><td>-1.5624543</td><td>-0.8851760</td></tr>\n",
       "\t<tr><td>-0.4170899</td><td> 0.2718880</td></tr>\n",
       "\t<tr><td> 1.0443557</td><td>-0.7341975</td></tr>\n",
       "\t<tr><td>-0.3155684</td><td> 0.8419834</td></tr>\n",
       "\t<tr><td>-1.7371238</td><td>-2.0371910</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " X & Y\\\\\n",
       "\\hline\n",
       "\t -0.8952509 & -0.2349235\\\\\n",
       "\t -1.5624543 & -0.8851760\\\\\n",
       "\t -0.4170899 &  0.2718880\\\\\n",
       "\t  1.0443557 & -0.7341975\\\\\n",
       "\t -0.3155684 &  0.8419834\\\\\n",
       "\t -1.7371238 & -2.0371910\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "X | Y | \n",
       "|---|---|---|---|---|---|\n",
       "| -0.8952509 | -0.2349235 | \n",
       "| -1.5624543 | -0.8851760 | \n",
       "| -0.4170899 |  0.2718880 | \n",
       "|  1.0443557 | -0.7341975 | \n",
       "| -0.3155684 |  0.8419834 | \n",
       "| -1.7371238 | -2.0371910 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  X          Y         \n",
       "1 -0.8952509 -0.2349235\n",
       "2 -1.5624543 -0.8851760\n",
       "3 -0.4170899  0.2718880\n",
       "4  1.0443557 -0.7341975\n",
       "5 -0.3155684  0.8419834\n",
       "6 -1.7371238 -2.0371910"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(Portfolio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we wish to invest a fixed sum of money in two financial assets that yield returns of $X$ and $Y$, respectively, where $X$ and $Y$ are random quantities. We will invest a fraction $\\alpha$ of our money in $X$, and will invest the remaining $1-\\alpha$ in $Y$. Since there is variability associated with the returns on these two assets, we wish to choose $\\alpha$ to minimize the total risk, or variance, of our investiment. In other words, we want to minimize $\\text{Var}(\\alpha X + (1-\\alpha)Y)$. One can show that the value that minimizes the risk is given by\n",
    "$$\n",
    "\\alpha = \\frac{\\sigma_{Y}^{2} - \\sigma_{XY}}\n",
    "              {\\sigma_{X}^{2} - \\sigma_{Y}^{2} \n",
    "                              - 2\\sigma_{XY}},\n",
    "$$\n",
    "where\n",
    "$\\sigma_{X}^{2} = \\text{Var}(X)$,\n",
    "$\\sigma_{Y}^{2} = \\text{Var}(Y)$, and\n",
    "$\\sigma_{XY} = \\text{Cov}(X, Y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.57583207459283"
      ],
      "text/latex": [
       "0.57583207459283"
      ],
      "text/markdown": [
       "0.57583207459283"
      ],
      "text/plain": [
       "[1] 0.5758321"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha.fn <- function(data, index) {\n",
    "    X <- data$X[index]\n",
    "    Y <- data$Y[index]\n",
    "    (var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2*cov(X, Y))\n",
    "}\n",
    "\n",
    "alpha.fn(Portfolio, 1:100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.596383302006392"
      ],
      "text/latex": [
       "0.596383302006392"
      ],
      "text/markdown": [
       "0.596383302006392"
      ],
      "text/plain": [
       "[1] 0.5963833"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "alpha.fn(Portfolio, sample(100, 100, replace = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Portfolio, statistic = alpha.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "     original        bias    std. error\n",
       "t1* 0.5758321 -7.315422e-05  0.08861826"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot(Portfolio, alpha.fn, R = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the Accuracy of a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>39.9358610211705</dd>\n",
       "\t<dt>horsepower</dt>\n",
       "\t\t<dd>-0.157844733353654</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 39.9358610211705\n",
       "\\item[horsepower] -0.157844733353654\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   39.9358610211705horsepower\n",
       ":   -0.157844733353654\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 39.9358610  -0.1578447 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot.fn <- function(data, index) {\n",
    "    coef(lm(mpg ~ horsepower, data = data, subset = index))\n",
    "}\n",
    "\n",
    "boot.fn(Auto, 1:392)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>38.7387133554397</dd>\n",
       "\t<dt>horsepower</dt>\n",
       "\t\t<dd>-0.14819518636376</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 38.7387133554397\n",
       "\\item[horsepower] -0.14819518636376\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   38.7387133554397horsepower\n",
       ":   -0.14819518636376\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 38.7387134  -0.1481952 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>40.0383085722796</dd>\n",
       "\t<dt>horsepower</dt>\n",
       "\t\t<dd>-0.159610359262947</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 40.0383085722796\n",
       "\\item[horsepower] -0.159610359262947\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   40.0383085722796horsepower\n",
       ":   -0.159610359262947\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 40.0383086  -0.1596104 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "boot.fn(Auto, sample(392, 392, replace = TRUE))\n",
    "boot.fn(Auto, sample(392, 392, replace = TRUE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Auto, statistic = boot.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "      original      bias    std. error\n",
       "t1* 39.9358610  0.02972191 0.860007896\n",
       "t2* -0.1578447 -0.00030823 0.007404467"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot(Auto, boot.fn, R = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>39.9358610   </td><td>0.717498656  </td><td> 55.65984    </td><td>1.220362e-187</td></tr>\n",
       "\t<tr><th scope=row>horsepower</th><td>-0.1578447   </td><td>0.006445501  </td><td>-24.48914    </td><td> 7.031989e-81</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n",
       "\\hline\n",
       "\t(Intercept) & 39.9358610    & 0.717498656   &  55.65984     & 1.220362e-187\\\\\n",
       "\thorsepower & -0.1578447    & 0.006445501   & -24.48914     &  7.031989e-81\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Estimate | Std. Error | t value | Pr(>|t|) | \n",
       "|---|---|\n",
       "| (Intercept) | 39.9358610    | 0.717498656   |  55.65984     | 1.220362e-187 | \n",
       "| horsepower | -0.1578447    | 0.006445501   | -24.48914     |  7.031989e-81 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "            Estimate   Std. Error  t value   Pr(>|t|)     \n",
       "(Intercept) 39.9358610 0.717498656  55.65984 1.220362e-187\n",
       "horsepower  -0.1578447 0.006445501 -24.48914  7.031989e-81"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lm(mpg ~ horsepower, data = Auto))$coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Auto, statistic = boot.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "        original        bias     std. error\n",
       "t1* 56.900099702  6.098115e-03 2.0944855842\n",
       "t2* -0.466189630 -1.777108e-04 0.0334123802\n",
       "t3*  0.001230536  1.324315e-06 0.0001208339"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot.fn <- function(data, index) {\n",
    "    coefficients(lm(mpg ~ horsepower + I(horsepower^2),\n",
    "                    data = data, subset = index))\n",
    "}\n",
    "\n",
    "set.seed(1)\n",
    "boot(Auto, boot.fn, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>56.900099702 </td><td>1.8004268063 </td><td> 31.60367    </td><td>1.740911e-109</td></tr>\n",
       "\t<tr><th scope=row>horsepower</th><td>-0.466189630 </td><td>0.0311246171 </td><td>-14.97816    </td><td> 2.289429e-40</td></tr>\n",
       "\t<tr><th scope=row>I(horsepower^2)</th><td> 0.001230536 </td><td>0.0001220759 </td><td> 10.08009    </td><td> 2.196340e-21</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n",
       "\\hline\n",
       "\t(Intercept) & 56.900099702  & 1.8004268063  &  31.60367     & 1.740911e-109\\\\\n",
       "\thorsepower & -0.466189630  & 0.0311246171  & -14.97816     &  2.289429e-40\\\\\n",
       "\tI(horsepower\\textasciicircum{}2) &  0.001230536  & 0.0001220759  &  10.08009     &  2.196340e-21\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Estimate | Std. Error | t value | Pr(>|t|) | \n",
       "|---|---|---|\n",
       "| (Intercept) | 56.900099702  | 1.8004268063  |  31.60367     | 1.740911e-109 | \n",
       "| horsepower | -0.466189630  | 0.0311246171  | -14.97816     |  2.289429e-40 | \n",
       "| I(horsepower^2) |  0.001230536  | 0.0001220759  |  10.08009     |  2.196340e-21 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "                Estimate     Std. Error   t value   Pr(>|t|)     \n",
       "(Intercept)     56.900099702 1.8004268063  31.60367 1.740911e-109\n",
       "horsepower      -0.466189630 0.0311246171 -14.97816  2.289429e-40\n",
       "I(horsepower^2)  0.001230536 0.0001220759  10.08009  2.196340e-21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lm(mpg ~ horsepower + I(horsepower^2),\n",
    "           data = Auto))$coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Chapter 4, we used logistic regression to predict the probability of **default** using **income** and **balance** on the **Default** data set .We will now estiamte the test error of thsi logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis.\n",
    "\n",
    "a) Fit a logistic regression model that uses **income** and **balance** to predict **default**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>default</th><th scope=col>student</th><th scope=col>balance</th><th scope=col>income</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>No       </td><td>No       </td><td> 729.5265</td><td>44361.625</td></tr>\n",
       "\t<tr><td>No       </td><td>Yes      </td><td> 817.1804</td><td>12106.135</td></tr>\n",
       "\t<tr><td>No       </td><td>No       </td><td>1073.5492</td><td>31767.139</td></tr>\n",
       "\t<tr><td>No       </td><td>No       </td><td> 529.2506</td><td>35704.494</td></tr>\n",
       "\t<tr><td>No       </td><td>No       </td><td> 785.6559</td><td>38463.496</td></tr>\n",
       "\t<tr><td>No       </td><td>Yes      </td><td> 919.5885</td><td> 7491.559</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " default & student & balance & income\\\\\n",
       "\\hline\n",
       "\t No        & No        &  729.5265 & 44361.625\\\\\n",
       "\t No        & Yes       &  817.1804 & 12106.135\\\\\n",
       "\t No        & No        & 1073.5492 & 31767.139\\\\\n",
       "\t No        & No        &  529.2506 & 35704.494\\\\\n",
       "\t No        & No        &  785.6559 & 38463.496\\\\\n",
       "\t No        & Yes       &  919.5885 &  7491.559\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "default | student | balance | income | \n",
       "|---|---|---|---|---|---|\n",
       "| No        | No        |  729.5265 | 44361.625 | \n",
       "| No        | Yes       |  817.1804 | 12106.135 | \n",
       "| No        | No        | 1073.5492 | 31767.139 | \n",
       "| No        | No        |  529.2506 | 35704.494 | \n",
       "| No        | No        |  785.6559 | 38463.496 | \n",
       "| No        | Yes       |  919.5885 |  7491.559 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  default student balance   income   \n",
       "1 No      No       729.5265 44361.625\n",
       "2 No      Yes      817.1804 12106.135\n",
       "3 No      No      1073.5492 31767.139\n",
       "4 No      No       529.2506 35704.494\n",
       "5 No      No       785.6559 38463.496\n",
       "6 No      Yes      919.5885  7491.559"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = default ~ income + balance, family = binomial, \n",
       "    data = Default)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.4725  -0.1444  -0.0574  -0.0211   3.7245  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -1.154e+01  4.348e-01 -26.545  < 2e-16 ***\n",
       "income       2.081e-05  4.985e-06   4.174 2.99e-05 ***\n",
       "balance      5.647e-03  2.274e-04  24.836  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 2920.6  on 9999  degrees of freedom\n",
       "Residual deviance: 1579.0  on 9997  degrees of freedom\n",
       "AIC: 1585\n",
       "\n",
       "Number of Fisher Scoring iterations: 8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit <- glm(default ~ income + balance,\n",
    "               family = binomial, data = Default)\n",
    "summary(glm.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps:\n",
    "\n",
    "- Split the sample set into a training set a validation set.\n",
    "- Fit a multiple logistic regression model using only the training observations.\n",
    "- Obtain a predictino of default status for each individual in the validiation set by computing the osterior probability of default for that individuals, and classifying the individual to the **default** category if the posterior probability is greater than 0.5.\n",
    "- Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "train <- sample(nrow(Default), nrow(Default) / 2,\n",
    "                replace = FALSE)\n",
    "X.train <- Default[train, ]\n",
    "X.test <- Default[-train, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = default ~ income + balance, family = binomial, \n",
       "    data = X.train)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.3583  -0.1268  -0.0475  -0.0165   3.8116  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -1.208e+01  6.658e-01 -18.148   <2e-16 ***\n",
       "income       1.858e-05  7.573e-06   2.454   0.0141 *  \n",
       "balance      6.053e-03  3.467e-04  17.457   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 1457.0  on 4999  degrees of freedom\n",
       "Residual deviance:  734.4  on 4997  degrees of freedom\n",
       "AIC: 740.4\n",
       "\n",
       "Number of Fisher Scoring iterations: 8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit <- glm(default ~ income + balance, \n",
    "               family = binomial, data = X.train)\n",
    "summary(glm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.pred <- predict(glm.fit, X.train, type = \"response\")\n",
    "test.pred <- predict(glm.fit, X.test, type = \"response\")\n",
    "\n",
    "train.class <- rep(\"No\", nrow(X.train))\n",
    "train.class[train.pred > 0.5] <- \"Yes\"\n",
    "\n",
    "test.class <- rep(\"No\", nrow(X.test))\n",
    "test.class[test.pred > 0.5] <- \"Yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.9756"
      ],
      "text/latex": [
       "0.9756"
      ],
      "text/markdown": [
       "0.9756"
      ],
      "text/plain": [
       "[1] 0.9756"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(train.class == X.train$default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.9714"
      ],
      "text/latex": [
       "0.9714"
      ],
      "text/markdown": [
       "0.9714"
      ],
      "text/plain": [
       "[1] 0.9714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(test.class == X.test$default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Repeat the process in b) three times, using three different splits of the observations into a training set and a validation set. Coment on the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 97.56% - Test accuracy: 97.14%\n",
      "Train accuracy: 97.44% - Test accuracy: 97.24%\n",
      "Train accuracy: 97.20% - Test accuracy: 97.52%\n"
     ]
    }
   ],
   "source": [
    "glm.try <- function(seed) {\n",
    "    set.seed(seed)\n",
    "    train <- sample(nrow(Default), nrow(Default) * 0.5,\n",
    "                    replace = FALSE)\n",
    "    X.train <- Default[train, ]\n",
    "    X.test <- Default[-train, ]\n",
    "    glm.fit <- glm(default ~ income + balance, \n",
    "                   family = binomial, data = X.train)\n",
    "    summary(glm.fit)\n",
    "    train.pred <- predict(glm.fit, X.train, type = \"response\")\n",
    "    test.pred <- predict(glm.fit, X.test, type = \"response\")\n",
    "\n",
    "    train.class <- rep(\"No\", nrow(X.train))\n",
    "    train.class[train.pred > 0.5] <- \"Yes\"\n",
    "    train.class <- factor(train.class)\n",
    "\n",
    "    test.class <- rep(\"No\", nrow(X.test))\n",
    "    test.class[test.pred > 0.5] <- \"Yes\"\n",
    "    test.class <- factor(test.class)\n",
    "    \n",
    "    train.acc <- mean(train.class == X.train$default)\n",
    "    test.acc <- mean(test.class == X.test$default)\n",
    "    \n",
    "    cat(sprintf(\"Train accuracy: %.2f%% - \", train.acc * 100))\n",
    "    cat(sprintf(\"Test accuracy: %.2f%%\\n\", test.acc * 100))\n",
    "}\n",
    "\n",
    "glm.try(1)\n",
    "glm.try(2)\n",
    "glm.try(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For three validation splits, our estimation ranged between 97.1% and 97.5%. But let’s note that’s not much better when we compare with a classifier that say nobody will ever default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.9666"
      ],
      "text/latex": [
       "0.9666"
      ],
      "text/markdown": [
       "0.9666"
      ],
      "text/plain": [
       "[1] 0.9666"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(\"No\" == X.test$default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Now consider a logistic regression model that predicts the probability of **default** using **income**, **balance**, and a dummy variable for **student**. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for **student** leads to a rediction n the test error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = default ~ income + balance + student, family = binomial, \n",
       "    data = X.train)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.2905  -0.1260  -0.0465  -0.0161   3.7715  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -1.147e+01  7.562e-01 -15.164   <2e-16 ***\n",
       "income       2.433e-06  1.256e-05   0.194    0.846    \n",
       "balance      6.124e-03  3.525e-04  17.373   <2e-16 ***\n",
       "studentYes  -5.608e-01  3.473e-01  -1.615    0.106    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 1456.95  on 4999  degrees of freedom\n",
       "Residual deviance:  731.81  on 4996  degrees of freedom\n",
       "AIC: 739.81\n",
       "\n",
       "Number of Fisher Scoring iterations: 8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "train <- sample(nrow(Default), nrow(Default) / 2,\n",
    "                replace = FALSE)\n",
    "X.train <- Default[train, ]\n",
    "X.test <- Default[-train, ]\n",
    "\n",
    "glm.fit <- glm(default ~ income + balance + student,\n",
    "               family = binomial, data = X.train)\n",
    "summary(glm.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a p-value of 0.106, we cannot reject the null hypothesis that the coefficient for **studentYes** is zero. This variable should not lead to a reducation in the test error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.9712"
      ],
      "text/latex": [
       "0.9712"
      ],
      "text/markdown": [
       "0.9712"
      ],
      "text/plain": [
       "[1] 0.9712"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.pred <- predict(glm.fit, X.test, type = \"response\")\n",
    "test.class <- rep(\"No\", nrow(X.test))\n",
    "test.class[test.pred > 0.5] <- \"Yes\"\n",
    "test.class <- factor(test.class)\n",
    "mean(test.class == X.test$default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the accuracy is very similar to the ones we got with a model that would not contain a dummy of **student**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue to consider the use of a logistic regression model to predict the probability of **default** using **income** and **balance** on the **Default** data set. In particular, we will now compute estimates for the standard errros of the **income** and **balance** logistic regression coefficients in two different ways:\n",
    "\n",
    "- using the bootstrap, and\n",
    "- using the standard formula for computing the standard errors in the `glm()` functin. Do not forget to set a random seed before beginning your analysis.\n",
    "\n",
    "a) Using the `summary()` and `glm()` functions, determine the estimated standard errors for the coefficients associated with **income** and **balance** in a multiple logistic regression model that uses both predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = default ~ income + balance, family = binomial, \n",
       "    data = Default)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.4725  -0.1444  -0.0574  -0.0211   3.7245  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -1.154e+01  4.348e-01 -26.545  < 2e-16 ***\n",
       "income       2.081e-05  4.985e-06   4.174 2.99e-05 ***\n",
       "balance      5.647e-03  2.274e-04  24.836  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 2920.6  on 9999  degrees of freedom\n",
       "Residual deviance: 1579.0  on 9997  degrees of freedom\n",
       "AIC: 1585\n",
       "\n",
       "Number of Fisher Scoring iterations: 8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit <- glm(default ~ income + balance, \n",
    "               family = binomial, data = Default)\n",
    "summary(glm.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard error of **income** coefficient is $\\widehat{SE}(\\beta_1) = 0.000005$, and for the **balance** coefficient is $\\widehat{SE}(\\beta_2) = 0.0002$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Write a function `boot.fn()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>-12.0820450308883</dd>\n",
       "\t<dt>income</dt>\n",
       "\t\t<dd>1.85814661031588e-05</dd>\n",
       "\t<dt>balance</dt>\n",
       "\t\t<dd>0.00605293526936792</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] -12.0820450308883\n",
       "\\item[income] 1.85814661031588e-05\n",
       "\\item[balance] 0.00605293526936792\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   -12.0820450308883income\n",
       ":   1.85814661031588e-05balance\n",
       ":   0.00605293526936792\n",
       "\n"
      ],
      "text/plain": [
       "  (Intercept)        income       balance \n",
       "-1.208205e+01  1.858147e-05  6.052935e-03 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot.fn <- function(data, index) {\n",
    "    glm.fit <- glm(default ~ income + balance,\n",
    "                   family = binomial, data = data, \n",
    "                   subset = index)\n",
    "    coef(glm.fit)\n",
    "}\n",
    "\n",
    "boot.fn(Default, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Default, statistic = boot.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "         original        bias     std. error\n",
       "t1* -1.154047e+01 -8.331926e-03 4.240329e-01\n",
       "t2*  2.080898e-05  5.792741e-08 4.590086e-06\n",
       "t3*  5.647103e-03  2.526993e-06 2.268457e-04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot(Default, boot.fn, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Method | income, $\\widehat{SE}(\\beta_1)$ | balance, $\\widehat{SE}(\\beta_2)$ \n",
    ":-- | :-- | :--\n",
    "standard  | 0.0000050 | 0.00023\n",
    "bootstrap | 0.0000053 | 0.00027\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bootstrap method found a very similar standard error,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOOCV on **Weekly** data set.\n",
    "\n",
    "a) Fit a logistic regression model that predicts **Direction** using **Lag1** and **Lag2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Year</th><th scope=col>Lag1</th><th scope=col>Lag2</th><th scope=col>Lag3</th><th scope=col>Lag4</th><th scope=col>Lag5</th><th scope=col>Volume</th><th scope=col>Today</th><th scope=col>Direction</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1990     </td><td> 0.816   </td><td> 1.572   </td><td>-3.936   </td><td>-0.229   </td><td>-3.484   </td><td>0.1549760</td><td>-0.270   </td><td>Down     </td></tr>\n",
       "\t<tr><td>1990     </td><td>-0.270   </td><td> 0.816   </td><td> 1.572   </td><td>-3.936   </td><td>-0.229   </td><td>0.1485740</td><td>-2.576   </td><td>Down     </td></tr>\n",
       "\t<tr><td>1990     </td><td>-2.576   </td><td>-0.270   </td><td> 0.816   </td><td> 1.572   </td><td>-3.936   </td><td>0.1598375</td><td> 3.514   </td><td>Up       </td></tr>\n",
       "\t<tr><td>1990     </td><td> 3.514   </td><td>-2.576   </td><td>-0.270   </td><td> 0.816   </td><td> 1.572   </td><td>0.1616300</td><td> 0.712   </td><td>Up       </td></tr>\n",
       "\t<tr><td>1990     </td><td> 0.712   </td><td> 3.514   </td><td>-2.576   </td><td>-0.270   </td><td> 0.816   </td><td>0.1537280</td><td> 1.178   </td><td>Up       </td></tr>\n",
       "\t<tr><td>1990     </td><td> 1.178   </td><td> 0.712   </td><td> 3.514   </td><td>-2.576   </td><td>-0.270   </td><td>0.1544440</td><td>-1.372   </td><td>Down     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllll}\n",
       " Year & Lag1 & Lag2 & Lag3 & Lag4 & Lag5 & Volume & Today & Direction\\\\\n",
       "\\hline\n",
       "\t 1990      &  0.816    &  1.572    & -3.936    & -0.229    & -3.484    & 0.1549760 & -0.270    & Down     \\\\\n",
       "\t 1990      & -0.270    &  0.816    &  1.572    & -3.936    & -0.229    & 0.1485740 & -2.576    & Down     \\\\\n",
       "\t 1990      & -2.576    & -0.270    &  0.816    &  1.572    & -3.936    & 0.1598375 &  3.514    & Up       \\\\\n",
       "\t 1990      &  3.514    & -2.576    & -0.270    &  0.816    &  1.572    & 0.1616300 &  0.712    & Up       \\\\\n",
       "\t 1990      &  0.712    &  3.514    & -2.576    & -0.270    &  0.816    & 0.1537280 &  1.178    & Up       \\\\\n",
       "\t 1990      &  1.178    &  0.712    &  3.514    & -2.576    & -0.270    & 0.1544440 & -1.372    & Down     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Year | Lag1 | Lag2 | Lag3 | Lag4 | Lag5 | Volume | Today | Direction | \n",
       "|---|---|---|---|---|---|\n",
       "| 1990      |  0.816    |  1.572    | -3.936    | -0.229    | -3.484    | 0.1549760 | -0.270    | Down      | \n",
       "| 1990      | -0.270    |  0.816    |  1.572    | -3.936    | -0.229    | 0.1485740 | -2.576    | Down      | \n",
       "| 1990      | -2.576    | -0.270    |  0.816    |  1.572    | -3.936    | 0.1598375 |  3.514    | Up        | \n",
       "| 1990      |  3.514    | -2.576    | -0.270    |  0.816    |  1.572    | 0.1616300 |  0.712    | Up        | \n",
       "| 1990      |  0.712    |  3.514    | -2.576    | -0.270    |  0.816    | 0.1537280 |  1.178    | Up        | \n",
       "| 1990      |  1.178    |  0.712    |  3.514    | -2.576    | -0.270    | 0.1544440 | -1.372    | Down      | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Year Lag1   Lag2   Lag3   Lag4   Lag5   Volume    Today  Direction\n",
       "1 1990  0.816  1.572 -3.936 -0.229 -3.484 0.1549760 -0.270 Down     \n",
       "2 1990 -0.270  0.816  1.572 -3.936 -0.229 0.1485740 -2.576 Down     \n",
       "3 1990 -2.576 -0.270  0.816  1.572 -3.936 0.1598375  3.514 Up       \n",
       "4 1990  3.514 -2.576 -0.270  0.816  1.572 0.1616300  0.712 Up       \n",
       "5 1990  0.712  3.514 -2.576 -0.270  0.816 0.1537280  1.178 Up       \n",
       "6 1990  1.178  0.712  3.514 -2.576 -0.270 0.1544440 -1.372 Down     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(Weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Direction ~ Lag1 + Lag2, family = binomial, data = Weekly)\n",
       "\n",
       "Deviance Residuals: \n",
       "   Min      1Q  Median      3Q     Max  \n",
       "-1.623  -1.261   1.001   1.083   1.506  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)  0.22122    0.06147   3.599 0.000319 ***\n",
       "Lag1        -0.03872    0.02622  -1.477 0.139672    \n",
       "Lag2         0.06025    0.02655   2.270 0.023232 *  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 1496.2  on 1088  degrees of freedom\n",
       "Residual deviance: 1488.2  on 1086  degrees of freedom\n",
       "AIC: 1494.2\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit <- glm(Direction ~ Lag1 + Lag2, \n",
    "               family = binomial, data = Weekly)\n",
    "summary(glm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Direction ~ Lag1 + Lag2, family = binomial, data = Weekly, \n",
       "    subset = -1)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.6258  -1.2617   0.9999   1.0819   1.5071  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)  0.22324    0.06150   3.630 0.000283 ***\n",
       "Lag1        -0.03843    0.02622  -1.466 0.142683    \n",
       "Lag2         0.06085    0.02656   2.291 0.021971 *  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 1494.6  on 1087  degrees of freedom\n",
       "Residual deviance: 1486.5  on 1085  degrees of freedom\n",
       "AIC: 1492.5\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit <- glm(Direction ~ Lag1 + Lag2, \n",
    "               family = binomial, data = Weekly,\n",
    "               subset = -1)\n",
    "summary(glm.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Use model from b) to predict the first obversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>1:</strong> 0.571392320520443"
      ],
      "text/latex": [
       "\\textbf{1:} 0.571392320520443"
      ],
      "text/markdown": [
       "**1:** 0.571392320520443"
      ],
      "text/plain": [
       "        1 \n",
       "0.5713923 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(glm.fit, Weekly[1, ], type = \"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Year</th><th scope=col>Lag1</th><th scope=col>Lag2</th><th scope=col>Lag3</th><th scope=col>Lag4</th><th scope=col>Lag5</th><th scope=col>Volume</th><th scope=col>Today</th><th scope=col>Direction</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1990    </td><td>0.816   </td><td>1.572   </td><td>-3.936  </td><td>-0.229  </td><td>-3.484  </td><td>0.154976</td><td>-0.27   </td><td>Down    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllll}\n",
       " Year & Lag1 & Lag2 & Lag3 & Lag4 & Lag5 & Volume & Today & Direction\\\\\n",
       "\\hline\n",
       "\t 1990     & 0.816    & 1.572    & -3.936   & -0.229   & -3.484   & 0.154976 & -0.27    & Down    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Year | Lag1 | Lag2 | Lag3 | Lag4 | Lag5 | Volume | Today | Direction | \n",
       "|---|\n",
       "| 1990     | 0.816    | 1.572    | -3.936   | -0.229   | -3.484   | 0.154976 | -0.27    | Down     | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Year Lag1  Lag2  Lag3   Lag4   Lag5   Volume   Today Direction\n",
       "1 1990 0.816 1.572 -3.936 -0.229 -3.484 0.154976 -0.27 Down     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Weekly[1, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model misclassified the observation, because the score of 0.57 with a threshold set at 0.5 will make the prediction as Up whereas the correct prediction is Down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a for loop from $i = 1$ to $i = n$, for the LOOCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Yes'"
      ],
      "text/latex": [
       "'Yes'"
      ],
      "text/markdown": [
       "'Yes'"
      ],
      "text/plain": [
       "[1] \"Yes\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c(\"No\", \"Yes\")[as.integer(0.6 > 0.5) + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error looking only the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.555555555555556"
      ],
      "text/latex": [
       "0.555555555555556"
      ],
      "text/markdown": [
       "0.555555555555556"
      ],
      "text/plain": [
       "[1] 0.5555556"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit <- glm(Direction ~ Lag1 + Lag2,\n",
    "               family = binomial, data = Weekly)\n",
    "pred <- predict(glm.fit, type = \"response\")\n",
    "class <- c(\"Down\", \"Up\")[as.integer(pred > 0.5) + 1]\n",
    "mean(class == Weekly$Direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error with a hold-out validation  set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.532110091743119"
      ],
      "text/latex": [
       "0.532110091743119"
      ],
      "text/markdown": [
       "0.532110091743119"
      ],
      "text/plain": [
       "[1] 0.5321101"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "train <- sample(nrow(Weekly), nrow(Weekly) * 0.5)\n",
    "glm.fit <- glm(Direction ~ Lag1 + Lag2,\n",
    "               family = binomial, data = Weekly,\n",
    "               subset = train)\n",
    "pred <- predict(glm.fit, Weekly[-train, ], type = \"response\")\n",
    "class <- c(\"Down\", \"Up\")[as.integer(pred > 0.5) + 1]\n",
    "mean(class == Weekly[-train, ]$Direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave-one-out approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.550045913682277"
      ],
      "text/latex": [
       "0.550045913682277"
      ],
      "text/markdown": [
       "0.550045913682277"
      ],
      "text/plain": [
       "[1] 0.5500459"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trials <- rep(NA, nrow(Weekly))\n",
    "for (i in 1:nrow(Weekly)) {\n",
    "    glm.fit <- glm(Direction ~ Lag1 + Lag2, \n",
    "                   family = binomial, data = Weekly,\n",
    "                   subset = -i)\n",
    "    pred <- predict(glm.fit, Weekly[i, ], type = \"response\")\n",
    "    class <- c(\"Down\", \"Up\")[as.integer(pred > 0.5) + 1]\n",
    "    trials[i] <- as.integer(class == Weekly[i, ]$Direction)\n",
    "}\n",
    "mean(trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The leave-one-out estimates that the accuracy is higher than the hold-out strategy, and lower than looking at the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation on a simulated data set.\n",
    "\n",
    "a) Generate a simulated data set as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "x <- rnorm(100)\n",
    "y <- x - 2*x^2 + rnorm(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model used to generate the data is\n",
    "$$\n",
    "x \\sim \\mathcal{N}(0, 1),\n",
    "$$\n",
    "and\n",
    "$$\n",
    "y = x - 2x^2 + \\epsilon,\n",
    "$$\n",
    "where $\\epsilon \\sim \\mathcal{N}(0, 1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Create a scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAHgCAIAAAADp837AAAACXBIWXMAABJ0AAASdAHeZh94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\nPMPAAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data <- data.frame(x=x, y=y)\n",
    "options(repr.plot.height = 4, repr.plot.width = 6)\n",
    "ggplot(data, aes(x, y)) + geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There’s a non-linear relationship between **x** and **y**, which is obvious by looking at how we generated the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Set a random seed and then compute the LOOCV for the following four models using least squares:\n",
    "\n",
    "- $Y = \\beta_0 + \\beta_1 X + \\epsilon$\n",
    "- $Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\epsilon$\n",
    "- $Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\epsilon$\n",
    "- $Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\beta_4 X^4 + \\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- data.frame(x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>7.28816160667281</li>\n",
       "\t<li>7.28474411546929</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 7.28816160667281\n",
       "\\item 7.28474411546929\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 7.28816160667281\n",
       "2. 7.28474411546929\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 7.288162 7.284744"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv.glm(data, glm(y ~ x))$delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.937423637615552</li>\n",
       "\t<li>0.937178917181124</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.937423637615552\n",
       "\\item 0.937178917181124\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.937423637615552\n",
       "2. 0.937178917181124\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.9374236 0.9371789"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv.glm(data, glm(y ~ poly(x, 2)))$delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.95662183010894</li>\n",
       "\t<li>0.956253813731321</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.95662183010894\n",
       "\\item 0.956253813731321\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.95662183010894\n",
       "2. 0.956253813731321\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.9566218 0.9562538"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv.glm(data, glm(y ~ poly(x, 3)))$delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.953904892744804</li>\n",
       "\t<li>0.953445283156601</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.953904892744804\n",
       "\\item 0.953445283156601\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.953904892744804\n",
       "2. 0.953445283156601\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.9539049 0.9534453"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv.glm(data, glm(y ~ poly(x, 4)))$delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Repeat c) usuing another random seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, because LOOCV does not depend on random numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Which of the models in c) had the smallest LOOCV error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model, with a quadratic term, because it allows the  linear model to fit nicely the  data, which has a non-linear relationship. With the quadratic term we get this scatterplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAHgCAIAAAADp837AAAACXBIWXMAABJ0AAASdAHeZh94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\nAABI7k8UfAX65lTvawAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(data.frame(x2=x^2, y=y), aes(x2, y)) + geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Comment on the statistical significance of the coefficient estimates that   results from fitting each of the models in c) using least squares. Do these results agree with the conclusions drawn based on the cross-validation results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = y ~ poly(x, 1))\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-9.5161  -0.6800   0.6812   1.5491   3.8183  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)   -1.550      0.260  -5.961 3.95e-08 ***\n",
       "poly(x, 1)     6.189      2.600   2.380   0.0192 *  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for gaussian family taken to be 6.760719)\n",
       "\n",
       "    Null deviance: 700.85  on 99  degrees of freedom\n",
       "Residual deviance: 662.55  on 98  degrees of freedom\n",
       "AIC: 478.88\n",
       "\n",
       "Number of Fisher Scoring iterations: 2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(glm(y ~ poly(x, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = y ~ poly(x, 2))\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.9650  -0.6254  -0.1288   0.5803   2.2700  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  -1.5500     0.0958  -16.18  < 2e-16 ***\n",
       "poly(x, 2)1   6.1888     0.9580    6.46 4.18e-09 ***\n",
       "poly(x, 2)2 -23.9483     0.9580  -25.00  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for gaussian family taken to be 0.9178258)\n",
       "\n",
       "    Null deviance: 700.852  on 99  degrees of freedom\n",
       "Residual deviance:  89.029  on 97  degrees of freedom\n",
       "AIC: 280.17\n",
       "\n",
       "Number of Fisher Scoring iterations: 2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(glm(y ~ poly(x, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = y ~ poly(x, 3))\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.9765  -0.6302  -0.1227   0.5545   2.2843  \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  -1.55002    0.09626 -16.102  < 2e-16 ***\n",
       "poly(x, 3)1   6.18883    0.96263   6.429 4.97e-09 ***\n",
       "poly(x, 3)2 -23.94830    0.96263 -24.878  < 2e-16 ***\n",
       "poly(x, 3)3   0.26411    0.96263   0.274    0.784    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for gaussian family taken to be 0.9266599)\n",
       "\n",
       "    Null deviance: 700.852  on 99  degrees of freedom\n",
       "Residual deviance:  88.959  on 96  degrees of freedom\n",
       "AIC: 282.09\n",
       "\n",
       "Number of Fisher Scoring iterations: 2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(glm(y ~ poly(x, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = y ~ poly(x, 4))\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.0550  -0.6212  -0.1567   0.5952   2.2267  \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  -1.55002    0.09591 -16.162  < 2e-16 ***\n",
       "poly(x, 4)1   6.18883    0.95905   6.453 4.59e-09 ***\n",
       "poly(x, 4)2 -23.94830    0.95905 -24.971  < 2e-16 ***\n",
       "poly(x, 4)3   0.26411    0.95905   0.275    0.784    \n",
       "poly(x, 4)4   1.25710    0.95905   1.311    0.193    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for gaussian family taken to be 0.9197797)\n",
       "\n",
       "    Null deviance: 700.852  on 99  degrees of freedom\n",
       "Residual deviance:  87.379  on 95  degrees of freedom\n",
       "AIC: 282.3\n",
       "\n",
       "Number of Fisher Scoring iterations: 2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(glm(y ~ poly(x, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the statistical significance agree with the conclusion that the best model is the model with the quadractic term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boston** data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"MASS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>crim</th><th scope=col>zn</th><th scope=col>indus</th><th scope=col>chas</th><th scope=col>nox</th><th scope=col>rm</th><th scope=col>age</th><th scope=col>dis</th><th scope=col>rad</th><th scope=col>tax</th><th scope=col>ptratio</th><th scope=col>black</th><th scope=col>lstat</th><th scope=col>medv</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.00632</td><td>18     </td><td>2.31   </td><td>0      </td><td>0.538  </td><td>6.575  </td><td>65.2   </td><td>4.0900 </td><td>1      </td><td>296    </td><td>15.3   </td><td>396.90 </td><td>4.98   </td><td>24.0   </td></tr>\n",
       "\t<tr><td>0.02731</td><td> 0     </td><td>7.07   </td><td>0      </td><td>0.469  </td><td>6.421  </td><td>78.9   </td><td>4.9671 </td><td>2      </td><td>242    </td><td>17.8   </td><td>396.90 </td><td>9.14   </td><td>21.6   </td></tr>\n",
       "\t<tr><td>0.02729</td><td> 0     </td><td>7.07   </td><td>0      </td><td>0.469  </td><td>7.185  </td><td>61.1   </td><td>4.9671 </td><td>2      </td><td>242    </td><td>17.8   </td><td>392.83 </td><td>4.03   </td><td>34.7   </td></tr>\n",
       "\t<tr><td>0.03237</td><td> 0     </td><td>2.18   </td><td>0      </td><td>0.458  </td><td>6.998  </td><td>45.8   </td><td>6.0622 </td><td>3      </td><td>222    </td><td>18.7   </td><td>394.63 </td><td>2.94   </td><td>33.4   </td></tr>\n",
       "\t<tr><td>0.06905</td><td> 0     </td><td>2.18   </td><td>0      </td><td>0.458  </td><td>7.147  </td><td>54.2   </td><td>6.0622 </td><td>3      </td><td>222    </td><td>18.7   </td><td>396.90 </td><td>5.33   </td><td>36.2   </td></tr>\n",
       "\t<tr><td>0.02985</td><td> 0     </td><td>2.18   </td><td>0      </td><td>0.458  </td><td>6.430  </td><td>58.7   </td><td>6.0622 </td><td>3      </td><td>222    </td><td>18.7   </td><td>394.12 </td><td>5.21   </td><td>28.7   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllll}\n",
       " crim & zn & indus & chas & nox & rm & age & dis & rad & tax & ptratio & black & lstat & medv\\\\\n",
       "\\hline\n",
       "\t 0.00632 & 18      & 2.31    & 0       & 0.538   & 6.575   & 65.2    & 4.0900  & 1       & 296     & 15.3    & 396.90  & 4.98    & 24.0   \\\\\n",
       "\t 0.02731 &  0      & 7.07    & 0       & 0.469   & 6.421   & 78.9    & 4.9671  & 2       & 242     & 17.8    & 396.90  & 9.14    & 21.6   \\\\\n",
       "\t 0.02729 &  0      & 7.07    & 0       & 0.469   & 7.185   & 61.1    & 4.9671  & 2       & 242     & 17.8    & 392.83  & 4.03    & 34.7   \\\\\n",
       "\t 0.03237 &  0      & 2.18    & 0       & 0.458   & 6.998   & 45.8    & 6.0622  & 3       & 222     & 18.7    & 394.63  & 2.94    & 33.4   \\\\\n",
       "\t 0.06905 &  0      & 2.18    & 0       & 0.458   & 7.147   & 54.2    & 6.0622  & 3       & 222     & 18.7    & 396.90  & 5.33    & 36.2   \\\\\n",
       "\t 0.02985 &  0      & 2.18    & 0       & 0.458   & 6.430   & 58.7    & 6.0622  & 3       & 222     & 18.7    & 394.12  & 5.21    & 28.7   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "crim | zn | indus | chas | nox | rm | age | dis | rad | tax | ptratio | black | lstat | medv | \n",
       "|---|---|---|---|---|---|\n",
       "| 0.00632 | 18      | 2.31    | 0       | 0.538   | 6.575   | 65.2    | 4.0900  | 1       | 296     | 15.3    | 396.90  | 4.98    | 24.0    | \n",
       "| 0.02731 |  0      | 7.07    | 0       | 0.469   | 6.421   | 78.9    | 4.9671  | 2       | 242     | 17.8    | 396.90  | 9.14    | 21.6    | \n",
       "| 0.02729 |  0      | 7.07    | 0       | 0.469   | 7.185   | 61.1    | 4.9671  | 2       | 242     | 17.8    | 392.83  | 4.03    | 34.7    | \n",
       "| 0.03237 |  0      | 2.18    | 0       | 0.458   | 6.998   | 45.8    | 6.0622  | 3       | 222     | 18.7    | 394.63  | 2.94    | 33.4    | \n",
       "| 0.06905 |  0      | 2.18    | 0       | 0.458   | 7.147   | 54.2    | 6.0622  | 3       | 222     | 18.7    | 396.90  | 5.33    | 36.2    | \n",
       "| 0.02985 |  0      | 2.18    | 0       | 0.458   | 6.430   | 58.7    | 6.0622  | 3       | 222     | 18.7    | 394.12  | 5.21    | 28.7    | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  crim    zn indus chas nox   rm    age  dis    rad tax ptratio black  lstat\n",
       "1 0.00632 18 2.31  0    0.538 6.575 65.2 4.0900 1   296 15.3    396.90 4.98 \n",
       "2 0.02731  0 7.07  0    0.469 6.421 78.9 4.9671 2   242 17.8    396.90 9.14 \n",
       "3 0.02729  0 7.07  0    0.469 7.185 61.1 4.9671 2   242 17.8    392.83 4.03 \n",
       "4 0.03237  0 2.18  0    0.458 6.998 45.8 6.0622 3   222 18.7    394.63 2.94 \n",
       "5 0.06905  0 2.18  0    0.458 7.147 54.2 6.0622 3   222 18.7    396.90 5.33 \n",
       "6 0.02985  0 2.18  0    0.458 6.430 58.7 6.0622 3   222 18.7    394.12 5.21 \n",
       "  medv\n",
       "1 24.0\n",
       "2 21.6\n",
       "3 34.7\n",
       "4 33.4\n",
       "5 36.2\n",
       "6 28.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(Boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Based on this data set, provide an estimate for the population mean of **medv**. Call this estimate $\\hat\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "22.5328063241107"
      ],
      "text/latex": [
       "22.5328063241107"
      ],
      "text/markdown": [
       "22.5328063241107"
      ],
      "text/plain": [
       "[1] 22.53281"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu = mean(Boston$medv)\n",
    "mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Provide an estimate of the standard error of $\\hat\\mu$. Interpret this result.\n",
    "\n",
    "*Hint: We can compute the standard error of the sample mean by diving the sample standard deviation by the square root of the number of observations.*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.408861147497535"
      ],
      "text/latex": [
       "0.408861147497535"
      ],
      "text/markdown": [
       "0.408861147497535"
      ],
      "text/plain": [
       "[1] 0.4088611"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "se = sd(Boston$medv) / sqrt(nrow(Boston))\n",
    "se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>21.7314384750155</li>\n",
       "\t<li>23.3341741732058</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 21.7314384750155\n",
       "\\item 23.3341741732058\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 21.7314384750155\n",
       "2. 23.3341741732058\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 21.73144 23.33417"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c(mu - 1.96*se, mu + 1.96*se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can say the the 95% confidence interval for the $\\mu$ is [21.73, 23.33]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Now estimate the standard error of $\\hat\\mu$ using the bootstrap. How does this compare to your answer from b)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Boston$medv, statistic = boot.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "    original     bias    std. error\n",
       "t1* 22.53281 0.00975415   0.4130483"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot.fn <- function(data, index) {\n",
    "    mean(data[index])\n",
    "}\n",
    "\n",
    "boot(Boston$medv, boot.fn, R = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>21.74522222</li>\n",
       "\t<li>23.32039778</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 21.74522222\n",
       "\\item 23.32039778\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 21.74522222\n",
       "2. 23.32039778\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 21.74522 23.32040"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu = 22.53281\n",
    "se = 0.4018305\n",
    "c(mu - 1.96*se, mu + 1.96*se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 95% confidence interval for $\\mu$ with the bootstrap now is [21.75, 23.32], which is slightly narrower than the one computed with a single sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Compare with the results obtain using `t.test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne Sample t-test\n",
       "\n",
       "data:  Boston$medv\n",
       "t = 55.111, df = 505, p-value < 2.2e-16\n",
       "alternative hypothesis: true mean is not equal to 0\n",
       "95 percent confidence interval:\n",
       " 21.72953 23.33608\n",
       "sample estimates:\n",
       "mean of x \n",
       " 22.53281 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(Boston$medv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimate with `t.test` is even larger than the first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Based on this data set, provide an estimate $\\hat\\mu_{med}$ for the median value of **medv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "21.2"
      ],
      "text/latex": [
       "21.2"
      ],
      "text/markdown": [
       "21.2"
      ],
      "text/plain": [
       "[1] 21.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "median(Boston$medv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) There’s no simple formula to compute the standard error of the median. Instead, estimate the standard error of the median using the bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Boston$medv, statistic = boot.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "    original  bias    std. error\n",
       "t1*     21.2 -0.0127   0.3869347"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot.fn <- function(data, index) {\n",
    "    median(data[index])\n",
    "}\n",
    "\n",
    "boot(Boston$medv, boot.fn, R = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>21.9448</li>\n",
       "\t<li>20.4552</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 21.9448\n",
       "\\item 20.4552\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 21.9448\n",
       "2. 20.4552\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 21.9448 20.4552"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c(21.2+1.96*0.38, 21.2-1.96*0.38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidence interval for the median value of **medv**, $\\mu_{med}$ is [21.95, 20.46]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
